%!TEX root = ../thesis.tex

\chapter{Аналіз існуючих програмних рішень}

У данному розділі описуються різноманітні підходи для автоматизації задачі читання
по губам.

\section{Розпізнавання слів класичними методами машинного навчання} 
Більшість сучасних методів для розпізнавання промовленного тексту не використовує технологій глубинного навчання. Такий підхід потребує дуже багато обчислень на стадії підготовки данних. Одні з основних предобчислень є:

\begin{itemize}
    \item image embeddings
    \item video embeddings
    \item optical flows
\end{itemize}

Такий підхід включає в себе багато алгоритмізованих підходів які є результатом спостережень та експериментів і він не є еффективним ані з точки зору швидкості обчислень ані з точки зору точності. 

\cite{goldschen1997continuous} було першою спробою зробити автоматизонае читання по губам на рівні речень. У цій імплементації використовано приховані марковські моделі (hidden Markov models) як модель для розпізнавання. 

\cite{neti2000audio} першими зробили аудіовізуальне розпізнавання мови у речення за допомогою прихованих марковські моделі (hidden Markov models) та власноруч побудованих дескриптораху, на наборі даних IBM ViaVoice. Автори покращують продуктивність розпізнавання мовлення в шумному оточенні шляхом злиття візуальних інформації із звуковою. Набір даних виступаючий для навчання містить $17111$ висловлень від $261$ людей (близько $34,9$ годин відео) і не є загальнодоступним. 

Автори зазначають що їхні візуальні результати не можуть бути інтерпретовані як тільки візуальне розпізнавання, оскільки вони використовували аудіодоріжку для підкріплення рішень своєї моделі. Використовуючи модель на основі прихованої марковської моделі автори отримали результати $ 91,62\%$ точності для моделі яка вивчається окремо для кожної людини, та $ 82,31 \%$  для загальної модели. Для перевірки було використано набір данних WER. Також ця модель показує $ 38,53 \%$, $ 16,77 \%$ на наборі данних WER з'єднаним з корпусом DIGIT, який містить промовленні цифри. 

Крім того такий підхід змушує адаптувати модель для кожної людини на якій він буде використовуватися. Генералізація модели для розпізнавання промовленного тексту незалежно від особи яка його промовляє залишаєтся невирішоную задачею. 

\section{Розпізнавання слів за допомогою глибокого навчання}

В останні роки було зроблено декілька спроб застосувати глибоке навчання для задачі розпізнавання промовленного тексту. Проте всі ці підходи виконують лише класифікацію слова або фонеми, і жоден з методів не робить повне передбачення послідовності речень. Данні підходи включають вивчення мультимодальних аудіовізуальних представлень, \cite{ngiam2011multimodal, sui2015listening, petridis2016deep}. недоліком цих робіт є те, що вони вокористовують традиційні підходи для класифікації слів та / або фонем які використовувалися виключно для аудіо обробки (наприклад, HMMs, GMM-HMMs і т.д.) \cite{almajai:2016, takashima2016audio, noda2014lipreading, koller2015deep}.

\cite{chung2016lip} пропонує просторові та просторово-часові згорткові нейронні мережі на основі VGG для класифікації слів. Архітектури перевірялася на наборі даних на рівні слова BBC TV (333 і 500 класів), але, як повідомлялося, їх просторово-часові моделі уступають просторовим архітектурам в середньому на $ 14 \$$. Крім того, їхні моделі не можуть обробляти змінні довжини послідовностей, і вони не намагаються передбачати послідовність на рівні речення. 

\cite{chung2016out} тренують аудіовізуальну модель для классифікації використовуючи вже натренеровані моделі для виділення image features з зображення обличчя людини. Отриманні фічі подають на вход до рекурентної нейроної мережі LSTM. Модель була перевірена на наборі данних OuluVS2.

\cite{wand2016lipreading} представляють модель основану на рекурентних неронних мережах, а зокрема LSTM. Недоліком данного рішення є те, що передбачення моделі базується не на реченнях, а на словах, також ця модель не є незалежною від особи, тому має бути дотренерована на окремих людях.

\cite{garglip} застосовують преднавчену на обличчях згорткову нейронну мережу VGG для классифікації слів та речень на наборі данних MIRACL-VC1. Недоліком цього дослідження є те, що набір данних включає в себе лише 10 слів та 10 реччень. Ще одним недоліком є те, що згорткова нейронна мережа VVG була навченою та використовувалася лише як feature extractor а усі передбачення вивчалися через рекурентну мережу на освнові LSTM, таким чином модель навчалася у два етапи а не в один. Найкраща модель мала $56.0\%$ точності на задачі классифікації слів та $44.5\%$ на задачі классифікації речень.

\section{Розпізнавання послідовності слів за допомогою глибокого навчання}

Напрямок автоматичного розпізнавання промовленого тексту (ASR) не мав би такого потенціалу без сучасних досліджень в області машинного навчання а точніше в області глибоких нейронних мереж, багато з яких були зроблені в котнексті ASR \cite{graves2006connectionist,dahl2012context,hinton2012deep}. Також суттевим є внесок розробки специфічних функій втрат (loss function) одною з яких є CTC loss, головною метою якої є вирішення проблеми які виникають при навчанні моделей на послідовностях данних таких як рукописний текст, аудіо зоапис, або як у випадку роспізнавання промовлених слів відео запис. 


\begin{comment}

LipNet is the first end-to-end model that performs sentence-level sequence prediction for visual speech recogntion. That is, we 
demonstrate the first work that takes as input as sequence of images and outputs a distribution over sequences of tokens; it is 
trained end-to-end using CTC and thus also does not require alignments.
\end{comment}